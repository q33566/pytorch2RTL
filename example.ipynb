{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da533128",
   "metadata": {},
   "source": [
    "# Objective: Turning pytorch model into RTL code\n",
    "## Overview\n",
    "1. Create a model using pytorch\n",
    "2. Export a model to ONNX (Open Neural Network Exchange)\n",
    "3. Convert ONNX → Vitis HLS Project\n",
    "4. Synthesize HLS C++ → RTL Verilog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71027c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_FILE_NAME = \"image_classifier_model.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f0952",
   "metadata": {},
   "source": [
    "### Create a model using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c19a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = (\n",
    "    torch.accelerator.current_accelerator().type\n",
    "    if torch.accelerator.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa330bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassifierModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ImageClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ImageClassifierModel().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82715e91",
   "metadata": {},
   "source": [
    "### Export a model to ONNX (Open Neural Network Exchange)\n",
    "- reference: https://docs.pytorch.org/tutorials/beginner/onnx/export_simple_model_to_onnx_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d4a8afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/g_sh7z092n5gtp0tk43127p40000gn/T/ipykernel_44458/1274601114.py:4: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    }
   ],
   "source": [
    "torch_model = ImageClassifierModel()\n",
    "# Create example inputs for exporting the model. The inputs should be a tuple of tensors.\n",
    "input_tensor = (torch.randn(1, 1, 32, 32),)\n",
    "torch.onnx.export(\n",
    "    torch_model,  # model to export\n",
    "    input_tensor,  # inputs of the model,\n",
    "    ONNX_FILE_NAME,  # filename of the ONNX model\n",
    "    input_names=[\"input\"],  # Rename inputs for the ONNX model\n",
    "    dynamo=False,  # True or False to select the exporter to use\n",
    "    # keep_initializers_as_inputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e1dbef",
   "metadata": {},
   "source": [
    "### Convert ONNX → Vitis HLS Project\n",
    "## Reference: \n",
    "1. https://fastmachinelearning.org/hls4ml/frontend/qonnx.html\n",
    "2. https://github.com/fastmachinelearning/hls4ml\n",
    "3. back end: https://fastmachinelearning.org/hls4ml/backend/vitis.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd124837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layers:  ['Add_2']\n",
      "Input shape: [1, 32, 32]\n",
      "Topology:\n",
      "Layer name: Transpose_0, layer type: Transpose, current shape: [[1, 1, 32, 32]]\n",
      "Layer name: Conv_0, layer type: Conv, current shape: [[1, 32, 32, 1], [6, 5, 5, 1], [6]]\n",
      "Layer name: Relu_0, layer type: Activation, current shape: [[1, 28, 28, 6]]\n",
      "Layer name: MaxPool_0, layer type: MaxPooling2D, current shape: [[1, 28, 28, 6]]\n",
      "Layer name: Conv_1, layer type: Conv, current shape: [[1, 14, 14, 6], [16, 5, 5, 6], [16]]\n",
      "Layer name: Relu_1, layer type: Activation, current shape: [[1, 10, 10, 16]]\n",
      "Layer name: MaxPool_1, layer type: MaxPooling2D, current shape: [[1, 10, 10, 16]]\n",
      "Layer name: Flatten_0, layer type: Reshape, current shape: [[1, 5, 5, 16]]\n",
      "Layer name: MatMul_0, layer type: MatMul, current shape: [[1, 400], [400, 120]]\n",
      "Layer name: Add_0, layer type: Merge, current shape: [[1, 120], [120]]\n",
      "Layer name: Relu_2, layer type: Activation, current shape: [[1, 120]]\n",
      "Layer name: MatMul_1, layer type: MatMul, current shape: [[1, 120], [120, 84]]\n",
      "Layer name: Add_1, layer type: Merge, current shape: [[1, 84], [84]]\n",
      "Layer name: Relu_3, layer type: Activation, current shape: [[1, 84]]\n",
      "Layer name: MatMul_2, layer type: MatMul, current shape: [[1, 84], [84, 10]]\n",
      "Layer name: Add_2, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Interpreting Model ...\n",
      "Output layers:  ['Add_2']\n",
      "Input shape: [1, 32, 32]\n",
      "Topology:\n",
      "Layer name: Transpose_0, layer type: Transpose, current shape: [[1, 1, 32, 32]]\n",
      "Layer name: Conv_0, layer type: Conv, current shape: [[1, 32, 32, 1], [6, 5, 5, 1], [6]]\n",
      "Layer name: Relu_0, layer type: Activation, current shape: [[1, 28, 28, 6]]\n",
      "Layer name: MaxPool_0, layer type: MaxPooling2D, current shape: [[1, 28, 28, 6]]\n",
      "Layer name: Conv_1, layer type: Conv, current shape: [[1, 14, 14, 6], [16, 5, 5, 6], [16]]\n",
      "Layer name: Relu_1, layer type: Activation, current shape: [[1, 10, 10, 16]]\n",
      "Layer name: MaxPool_1, layer type: MaxPooling2D, current shape: [[1, 10, 10, 16]]\n",
      "Layer name: Flatten_0, layer type: Reshape, current shape: [[1, 5, 5, 16]]\n",
      "Layer name: MatMul_0, layer type: MatMul, current shape: [[1, 400], [400, 120]]\n",
      "Layer name: Add_0, layer type: Merge, current shape: [[1, 120], [120]]\n",
      "Layer name: Relu_2, layer type: Activation, current shape: [[1, 120]]\n",
      "Layer name: MatMul_1, layer type: MatMul, current shape: [[1, 120], [120, 84]]\n",
      "Layer name: Add_1, layer type: Merge, current shape: [[1, 84], [84]]\n",
      "Layer name: Relu_3, layer type: Activation, current shape: [[1, 84]]\n",
      "Layer name: MatMul_2, layer type: MatMul, current shape: [[1, 84], [84, 10]]\n",
      "Layer name: Add_2, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Creating HLS model\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:21:\n",
      "In file included from firmware/ap_types/ap_fixed_base.h:25:\n",
      "In file included from firmware/ap_types/ap_int.h:319:\n",
      "firmware/ap_types/ap_int_special.h:60:7: error: reference to 'complex' is ambiguous\n",
      "   60 | class complex<ap_int<_AP_W> > {\n",
      "      |       ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__fwd/complex.h:22:28: note: candidate found by name lookup is 'std::__1::complex'\n",
      "   22 | class _LIBCPP_TEMPLATE_VIS complex;\n",
      "      |                            ^\n",
      "firmware/ap_types/ap_int_special.h:32:30: note: candidate found by name lookup is 'std::complex'\n",
      "   32 | template<typename _Tp> class complex;\n",
      "      |                              ^\n",
      "firmware/ap_types/ap_int_special.h:193:30: error: reference to 'complex' is ambiguous\n",
      "  193 | inline bool operator==(const complex<ap_int<_AP_W> > &__x, const ap_int<_AP_W> &__y) {\n",
      "      |                              ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__fwd/complex.h:22:28: note: candidate found by name lookup is 'std::__1::complex'\n",
      "   22 | class _LIBCPP_TEMPLATE_VIS complex;\n",
      "      |                            ^\n",
      "firmware/ap_types/ap_int_special.h:32:30: note: candidate found by name lookup is 'std::complex'\n",
      "   32 | template<typename _Tp> class complex;\n",
      "      |                              ^\n",
      "firmware/ap_types/ap_int_special.h:200:56: error: reference to 'complex' is ambiguous\n",
      "  200 | inline bool operator==(const ap_int<_AP_W> &__x, const complex<ap_int<_AP_W> > &__y) {\n",
      "      |                                                        ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__fwd/complex.h:22:28: note: candidate found by name lookup is 'std::__1::complex'\n",
      "   22 | class _LIBCPP_TEMPLATE_VIS complex;\n",
      "      |                            ^\n",
      "firmware/ap_types/ap_int_special.h:32:30: note: candidate found by name lookup is 'std::complex'\n",
      "   32 | template<typename _Tp> class complex;\n",
      "      |                              ^\n",
      "firmware/ap_types/ap_int_special.h:207:30: error: reference to 'complex' is ambiguous\n",
      "  207 | inline bool operator!=(const complex<ap_int<_AP_W> > &__x, const ap_int<_AP_W> &__y) {\n",
      "      |                              ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__fwd/complex.h:22:28: note: candidate found by name lookup is 'std::__1::complex'\n",
      "   22 | class _LIBCPP_TEMPLATE_VIS complex;\n",
      "      |                            ^\n",
      "firmware/ap_types/ap_int_special.h:32:30: note: candidate found by name lookup is 'std::complex'\n",
      "   32 | template<typename _Tp> class complex;\n",
      "      |                              ^\n",
      "firmware/ap_types/ap_int_special.h:214:56: error: reference to 'complex' is ambiguous\n",
      "  214 | inline bool operator!=(const ap_int<_AP_W> &__x, const complex<ap_int<_AP_W> > &__y) {\n",
      "      |                                                        ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__fwd/complex.h:22:28: note: candidate found by name lookup is 'std::__1::complex'\n",
      "   22 | class _LIBCPP_TEMPLATE_VIS complex;\n",
      "      |                            ^\n",
      "firmware/ap_types/ap_int_special.h:32:30: note: candidate found by name lookup is 'std::complex'\n",
      "   32 | template<typename _Tp> class complex;\n",
      "      |                              ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:356:\n",
      "firmware/ap_types/ap_fixed_special.h:60:7: error: reference to 'complex' is ambiguous\n",
      "   60 | class complex<ap_fixed<_AP_W, _AP_I, _AP_Q, _AP_O, _AP_N> > {\n",
      "      |       ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__fwd/complex.h:22:28: note: candidate found by name lookup is 'std::__1::complex'\n",
      "   22 | class _LIBCPP_TEMPLATE_VIS complex;\n",
      "      |                            ^\n",
      "firmware/ap_types/ap_int_special.h:32:30: note: candidate found by name lookup is 'std::complex'\n",
      "   32 | template<typename _Tp> class complex;\n",
      "      |                              ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:356:\n",
      "firmware/ap_types/ap_fixed_special.h:193:11: error: reference to 'complex' is ambiguous\n",
      "  193 |     const complex<ap_fixed<_AP_W, _AP_I, _AP_Q, _AP_O, _AP_N> > &__x,\n",
      "      |           ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__fwd/complex.h:22:28: note: candidate found by name lookup is 'std::__1::complex'\n",
      "   22 | class _LIBCPP_TEMPLATE_VIS complex;\n",
      "      |                            ^\n",
      "firmware/ap_types/ap_int_special.h:32:30: note: candidate found by name lookup is 'std::complex'\n",
      "   32 | template<typename _Tp> class complex;\n",
      "      |                              ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:356:\n",
      "firmware/ap_types/ap_fixed_special.h:203:11: error: reference to 'complex' is ambiguous\n",
      "  203 |     const complex<ap_fixed<_AP_W, _AP_I, _AP_Q, _AP_O, _AP_N> > &__y) {\n",
      "      |           ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__fwd/complex.h:22:28: note: candidate found by name lookup is 'std::__1::complex'\n",
      "   22 | class _LIBCPP_TEMPLATE_VIS complex;\n",
      "      |                            ^\n",
      "firmware/ap_types/ap_int_special.h:32:30: note: candidate found by name lookup is 'std::complex'\n",
      "   32 | template<typename _Tp> class complex;\n",
      "      |                              ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:356:\n",
      "firmware/ap_types/ap_fixed_special.h:211:11: error: reference to 'complex' is ambiguous\n",
      "  211 |     const complex<ap_fixed<_AP_W, _AP_I, _AP_Q, _AP_O, _AP_N> > &__x,\n",
      "      |           ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__fwd/complex.h:22:28: note: candidate found by name lookup is 'std::__1::complex'\n",
      "   22 | class _LIBCPP_TEMPLATE_VIS complex;\n",
      "      |                            ^\n",
      "firmware/ap_types/ap_int_special.h:32:30: note: candidate found by name lookup is 'std::complex'\n",
      "   32 | template<typename _Tp> class complex;\n",
      "      |                              ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:356:\n",
      "firmware/ap_types/ap_fixed_special.h:221:11: error: reference to 'complex' is ambiguous\n",
      "  221 |     const complex<ap_fixed<_AP_W, _AP_I, _AP_Q, _AP_O, _AP_N> > &__y) {\n",
      "      |           ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__fwd/complex.h:22:28: note: candidate found by name lookup is 'std::__1::complex'\n",
      "   22 | class _LIBCPP_TEMPLATE_VIS complex;\n",
      "      |                            ^\n",
      "firmware/ap_types/ap_int_special.h:32:30: note: candidate found by name lookup is 'std::complex'\n",
      "   32 | template<typename _Tp> class complex;\n",
      "      |                              ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:20:\n",
      "In file included from firmware/ap_types/ap_common.h:252:\n",
      "firmware/ap_types/etc/ap_private.h:3248:43: warning: arithmetic between different enumeration types ('ap_private<65, false>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3025:3)' and 'ap_private<65, false>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3160:3)') is deprecated [-Wdeprecated-anon-enum-enum-conversion]\n",
      " 3248 |       memcpy(pVal, that.get_pVal(), _AP_N * APINT_WORD_SIZE);\n",
      "      |                                     ~~~~~ ^ ~~~~~~~~~~~~~~~\n",
      "firmware/ap_types/ap_common.h:245:8: note: in instantiation of member function 'ap_private<65, false>::ap_private' requested here\n",
      "  245 | struct ssdm_int_sim {\n",
      "      |        ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:20:\n",
      "In file included from firmware/ap_types/ap_common.h:252:\n",
      "firmware/ap_types/etc/ap_private.h:3248:43: warning: arithmetic between different enumeration types ('ap_private<66, true>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3025:3)' and 'ap_private<66, true>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3160:3)') is deprecated [-Wdeprecated-anon-enum-enum-conversion]\n",
      " 3248 |       memcpy(pVal, that.get_pVal(), _AP_N * APINT_WORD_SIZE);\n",
      "      |                                     ~~~~~ ^ ~~~~~~~~~~~~~~~\n",
      "firmware/ap_types/etc/ap_private.h:3873:12: note: in instantiation of member function 'ap_private<66, true>::ap_private' requested here\n",
      " 3873 |     return Result;\n",
      "      |            ^\n",
      "firmware/ap_types/ap_int_base.h:1321:11: note: in instantiation of function template specialization 'ap_private<65, true>::operator-<65, true>' requested here\n",
      " 1321 | OP_BIN_AP(-, minus)\n",
      "      |           ^\n",
      "firmware/ap_types/ap_int_base.h:1438:1: note: in instantiation of function template specialization 'operator-<11, false, 64, true>' requested here\n",
      " 1438 | ALL_OP_BIN_WITH_INT(long, _AP_SIZE_long, true)\n",
      "      | ^\n",
      "firmware/ap_types/ap_int_base.h:1423:19: note: expanded from macro 'ALL_OP_BIN_WITH_INT'\n",
      " 1423 |   OP_BIN_WITH_INT(-, C_TYPE, _AP_W2, _AP_S2, minus) \\\n",
      "      |                   ^\n",
      "firmware/ap_types/ap_fixed_base.h:528:19: note: in instantiation of function template specialization 'operator-<11, false>' requested here\n",
      "  528 |     exp = exp_tmp - DOUBLE_BIAS;\n",
      "      |                   ^\n",
      "firmware/ap_types/ap_fixed_base.h:2081:7: note: in instantiation of member function 'ap_fixed_base<16, 6>::ap_fixed_base' requested here\n",
      " 2081 |   x = ap_fixed_base<_AP_W, _AP_I, _AP_S, _AP_Q, _AP_O, _AP_N>(d);\n",
      "      |       ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/istream:1158:8: note: in instantiation of function template specialization 'operator>><16, 6, true, AP_TRN, AP_WRAP, 0>' requested here\n",
      " 1158 |   __is >> std::forward<_Tp>(__x);\n",
      "      |        ^\n",
      "firmware/nnet_utils/nnet_helpers.h:39:39: note: in instantiation of function template specialization 'std::__1::operator>><std::istringstream, ap_fixed<16, 6> &, 0>' requested here\n",
      "   39 |             std::istringstream(token) >> w[i];\n",
      "      |                                       ^\n",
      "firmware/myproject.cpp:20:15: note: in instantiation of function template specialization 'nnet::load_weights_from_txt<ap_fixed<16, 6>, 150UL>' requested here\n",
      "   20 |         nnet::load_weights_from_txt<model_default_t, 150>(w34, \"w34.txt\");\n",
      "      |               ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:20:\n",
      "In file included from firmware/ap_types/ap_common.h:252:\n",
      "firmware/ap_types/etc/ap_private.h:4549:58: warning: arithmetic between different enumeration types ('ap_private<65, true>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3025:3)' and 'ap_private<65, true>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3160:3)') is deprecated [-Wdeprecated-anon-enum-enum-conversion]\n",
      " 4549 |     if (this != &RHS) memcpy(pVal, RHS.get_pVal(), _AP_N * APINT_WORD_SIZE);\n",
      "      |                                                    ~~~~~ ^ ~~~~~~~~~~~~~~~\n",
      "firmware/ap_types/ap_int.h:92:13: note: in instantiation of member function 'ap_private<65, true>::operator=' requested here\n",
      "   92 |     Base::V = op.V;\n",
      "      |             ^\n",
      "firmware/ap_types/ap_int_base.h:1321:1: note: in instantiation of function template specialization 'ap_int<65>::ap_int<65, true>' requested here\n",
      " 1321 | OP_BIN_AP(-, minus)\n",
      "      | ^\n",
      "firmware/ap_types/ap_int_base.h:1316:12: note: expanded from macro 'OP_BIN_AP'\n",
      " 1316 |     return ret;                                                               \\\n",
      "      |            ^\n",
      "firmware/ap_types/ap_int_base.h:1438:1: note: in instantiation of function template specialization 'operator-<11, false, 64, true>' requested here\n",
      " 1438 | ALL_OP_BIN_WITH_INT(long, _AP_SIZE_long, true)\n",
      "      | ^\n",
      "firmware/ap_types/ap_int_base.h:1423:19: note: expanded from macro 'ALL_OP_BIN_WITH_INT'\n",
      " 1423 |   OP_BIN_WITH_INT(-, C_TYPE, _AP_W2, _AP_S2, minus) \\\n",
      "      |                   ^\n",
      "firmware/ap_types/ap_fixed_base.h:528:19: note: in instantiation of function template specialization 'operator-<11, false>' requested here\n",
      "  528 |     exp = exp_tmp - DOUBLE_BIAS;\n",
      "      |                   ^\n",
      "firmware/ap_types/ap_fixed_base.h:2081:7: note: in instantiation of member function 'ap_fixed_base<16, 6>::ap_fixed_base' requested here\n",
      " 2081 |   x = ap_fixed_base<_AP_W, _AP_I, _AP_S, _AP_Q, _AP_O, _AP_N>(d);\n",
      "      |       ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/istream:1158:8: note: in instantiation of function template specialization 'operator>><16, 6, true, AP_TRN, AP_WRAP, 0>' requested here\n",
      " 1158 |   __is >> std::forward<_Tp>(__x);\n",
      "      |        ^\n",
      "firmware/nnet_utils/nnet_helpers.h:39:39: note: in instantiation of function template specialization 'std::__1::operator>><std::istringstream, ap_fixed<16, 6> &, 0>' requested here\n",
      "   39 |             std::istringstream(token) >> w[i];\n",
      "      |                                       ^\n",
      "firmware/myproject.cpp:20:15: note: in instantiation of function template specialization 'nnet::load_weights_from_txt<ap_fixed<16, 6>, 150UL>' requested here\n",
      "   20 |         nnet::load_weights_from_txt<model_default_t, 150>(w34, \"w34.txt\");\n",
      "      |               ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:20:\n",
      "In file included from firmware/ap_types/ap_common.h:252:\n",
      "firmware/ap_types/etc/ap_private.h:3248:43: warning: arithmetic between different enumeration types ('ap_private<65, true>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3025:3)' and 'ap_private<65, true>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3160:3)') is deprecated [-Wdeprecated-anon-enum-enum-conversion]\n",
      " 3248 |       memcpy(pVal, that.get_pVal(), _AP_N * APINT_WORD_SIZE);\n",
      "      |                                     ~~~~~ ^ ~~~~~~~~~~~~~~~\n",
      "firmware/ap_types/etc/ap_private.h:1922:14: note: in instantiation of member function 'ap_private<65, true>::ap_private' requested here\n",
      " 1922 |       return Ret;\n",
      "      |              ^\n",
      "firmware/ap_types/etc/ap_private.h:6897:1: note: in instantiation of function template specialization 'ap_private<64, false>::operator&<64, true>' requested here\n",
      " 6897 | OPS_MIX_INT(ap_slong, sizeof(ap_slong) * 8, true)\n",
      "      | ^\n",
      "firmware/ap_types/etc/ap_private.h:6863:3: note: expanded from macro 'OPS_MIX_INT'\n",
      " 6863 |   OP_BIN_MIX_INT(&, C_TYPE, (_AP_W2), (_AP_S2), logic)   \\\n",
      "      |   ^\n",
      "firmware/ap_types/etc/ap_private.h:6806:15: note: expanded from macro 'OP_BIN_MIX_INT'\n",
      " 6806 |     return op.operator BIN_OP(ap_private<_AP_WI, _AP_SI>(i_op));               \\\n",
      "      |               ^\n",
      "firmware/ap_types/ap_fixed_base.h:536:17: note: in instantiation of function template specialization 'operator&<64, false>' requested here\n",
      "  536 |     if ((ireg.V & 0x7fffffffffffffffLL) == 0) {\n",
      "      |                 ^\n",
      "firmware/ap_types/ap_fixed_base.h:2081:7: note: in instantiation of member function 'ap_fixed_base<16, 6>::ap_fixed_base' requested here\n",
      " 2081 |   x = ap_fixed_base<_AP_W, _AP_I, _AP_S, _AP_Q, _AP_O, _AP_N>(d);\n",
      "      |       ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/istream:1158:8: note: in instantiation of function template specialization 'operator>><16, 6, true, AP_TRN, AP_WRAP, 0>' requested here\n",
      " 1158 |   __is >> std::forward<_Tp>(__x);\n",
      "      |        ^\n",
      "firmware/nnet_utils/nnet_helpers.h:39:39: note: in instantiation of function template specialization 'std::__1::operator>><std::istringstream, ap_fixed<16, 6> &, 0>' requested here\n",
      "   39 |             std::istringstream(token) >> w[i];\n",
      "      |                                       ^\n",
      "firmware/myproject.cpp:20:15: note: in instantiation of function template specialization 'nnet::load_weights_from_txt<ap_fixed<16, 6>, 150UL>' requested here\n",
      "   20 |         nnet::load_weights_from_txt<model_default_t, 150>(w34, \"w34.txt\");\n",
      "      |               ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:20:\n",
      "In file included from firmware/ap_types/ap_common.h:252:\n",
      "firmware/ap_types/etc/ap_private.h:3849:3: warning: arithmetic between different enumeration types ('ap_private<65, true>::RType<64, true>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3121:5)' and 'ap_private<65, true>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3160:3)') is deprecated [-Wdeprecated-anon-enum-enum-conversion]\n",
      " 3849 |   OP_BIN_LOGIC_AP(&);\n",
      "      |   ^~~~~~~~~~~~~~~~~~\n",
      "firmware/ap_types/etc/ap_private.h:3817:50: note: expanded from macro 'OP_BIN_LOGIC_AP'\n",
      " 3817 |       numWords = (RType<_AP_W1, _AP_S1>::logic_w + APINT_BITS_PER_WORD - 1) / \\\n",
      "      |                   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^ ~~~~~~~~~~~~~~~~~~~\n",
      "firmware/ap_types/etc/ap_private.h:1925:18: note: in instantiation of function template specialization 'ap_private<65, true>::operator&<64, true>' requested here\n",
      " 1925 |       return Ret & RHS;\n",
      "      |                  ^\n",
      "firmware/ap_types/etc/ap_private.h:6897:1: note: in instantiation of function template specialization 'ap_private<64, false>::operator&<64, true>' requested here\n",
      " 6897 | OPS_MIX_INT(ap_slong, sizeof(ap_slong) * 8, true)\n",
      "      | ^\n",
      "firmware/ap_types/etc/ap_private.h:6863:3: note: expanded from macro 'OPS_MIX_INT'\n",
      " 6863 |   OP_BIN_MIX_INT(&, C_TYPE, (_AP_W2), (_AP_S2), logic)   \\\n",
      "      |   ^\n",
      "firmware/ap_types/etc/ap_private.h:6806:15: note: expanded from macro 'OP_BIN_MIX_INT'\n",
      " 6806 |     return op.operator BIN_OP(ap_private<_AP_WI, _AP_SI>(i_op));               \\\n",
      "      |               ^\n",
      "firmware/ap_types/ap_fixed_base.h:536:17: note: in instantiation of function template specialization 'operator&<64, false>' requested here\n",
      "  536 |     if ((ireg.V & 0x7fffffffffffffffLL) == 0) {\n",
      "      |                 ^\n",
      "firmware/ap_types/ap_fixed_base.h:2081:7: note: in instantiation of member function 'ap_fixed_base<16, 6>::ap_fixed_base' requested here\n",
      " 2081 |   x = ap_fixed_base<_AP_W, _AP_I, _AP_S, _AP_Q, _AP_O, _AP_N>(d);\n",
      "      |       ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/istream:1158:8: note: in instantiation of function template specialization 'operator>><16, 6, true, AP_TRN, AP_WRAP, 0>' requested here\n",
      " 1158 |   __is >> std::forward<_Tp>(__x);\n",
      "      |        ^\n",
      "firmware/nnet_utils/nnet_helpers.h:39:39: note: in instantiation of function template specialization 'std::__1::operator>><std::istringstream, ap_fixed<16, 6> &, 0>' requested here\n",
      "   39 |             std::istringstream(token) >> w[i];\n",
      "      |                                       ^\n",
      "firmware/myproject.cpp:20:15: note: in instantiation of function template specialization 'nnet::load_weights_from_txt<ap_fixed<16, 6>, 150UL>' requested here\n",
      "   20 |         nnet::load_weights_from_txt<model_default_t, 150>(w34, \"w34.txt\");\n",
      "      |               ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:20:\n",
      "In file included from firmware/ap_types/ap_common.h:252:\n",
      "firmware/ap_types/etc/ap_private.h:5399:28: warning: arithmetic between different enumeration types ('ap_private<65, false>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3025:3)' and 'ap_private<65, false>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3160:3)') is deprecated [-Wdeprecated-anon-enum-enum-conversion]\n",
      " 5399 |       msw_bits = (BitWidth % APINT_BITS_PER_WORD)\n",
      "      |                   ~~~~~~~~ ^ ~~~~~~~~~~~~~~~~~~~\n",
      "firmware/ap_types/etc/ap_private.h:5336:32: note: in instantiation of member function 'ap_private<65, false>::countLeadingZeros' requested here\n",
      " 5336 |     uint32_t bits = BitWidth - countLeadingZeros();\n",
      "      |                                ^\n",
      "firmware/ap_types/etc/ap_private.h:4023:19: note: in instantiation of member function 'ap_private<65, false>::getActiveBits' requested here\n",
      " 4023 |     uint32_t n1 = getActiveBits();\n",
      "      |                   ^\n",
      "firmware/ap_types/etc/ap_private.h:4046:16: note: in instantiation of member function 'ap_private<65, false>::operator==' requested here\n",
      " 4046 |     return lhs == rhs;\n",
      "      |                ^\n",
      "firmware/ap_types/etc/ap_private.h:6893:1: note: in instantiation of function template specialization 'ap_private<65, true>::operator==<32, true>' requested here\n",
      " 6893 | OPS_MIX_INT(int, sizeof(int) * 8, true)\n",
      "      | ^\n",
      "firmware/ap_types/etc/ap_private.h:6884:3: note: expanded from macro 'OPS_MIX_INT'\n",
      " 6884 |   OP_REL_MIX_INT(==, C_TYPE, (_AP_W2), (_AP_S2))         \\\n",
      "      |   ^\n",
      "firmware/ap_types/etc/ap_private.h:6813:15: note: expanded from macro 'OP_REL_MIX_INT'\n",
      " 6813 |     return op.operator REL_OP(ap_private<_AP_W2, _AP_S2>(op2));            \\\n",
      "      |               ^\n",
      "firmware/ap_types/ap_fixed_base.h:536:41: note: in instantiation of function template specialization 'operator==<65, true>' requested here\n",
      "  536 |     if ((ireg.V & 0x7fffffffffffffffLL) == 0) {\n",
      "      |                                         ^\n",
      "firmware/ap_types/ap_fixed_base.h:2081:7: note: in instantiation of member function 'ap_fixed_base<16, 6>::ap_fixed_base' requested here\n",
      " 2081 |   x = ap_fixed_base<_AP_W, _AP_I, _AP_S, _AP_Q, _AP_O, _AP_N>(d);\n",
      "      |       ^\n",
      "/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/istream:1158:8: note: in instantiation of function template specialization 'operator>><16, 6, true, AP_TRN, AP_WRAP, 0>' requested here\n",
      " 1158 |   __is >> std::forward<_Tp>(__x);\n",
      "      |        ^\n",
      "firmware/nnet_utils/nnet_helpers.h:39:39: note: in instantiation of function template specialization 'std::__1::operator>><std::istringstream, ap_fixed<16, 6> &, 0>' requested here\n",
      "   39 |             std::istringstream(token) >> w[i];\n",
      "      |                                       ^\n",
      "firmware/myproject.cpp:20:15: note: in instantiation of function template specialization 'nnet::load_weights_from_txt<ap_fixed<16, 6>, 150UL>' requested here\n",
      "   20 |         nnet::load_weights_from_txt<model_default_t, 150>(w34, \"w34.txt\");\n",
      "      |               ^\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "In file included from firmware/myproject.h:4:\n",
      "In file included from firmware/ap_types/ap_fixed.h:20:\n",
      "In file included from firmware/ap_types/ap_common.h:252:\n",
      "firmware/ap_types/etc/ap_private.h:5400:34: warning: arithmetic between different enumeration types ('ap_private<65, false>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3025:3)' and 'ap_private<65, false>::(unnamed enum at firmware/ap_types/etc/ap_private.h:3160:3)') is deprecated [-Wdeprecated-anon-enum-enum-conversion]\n",
      " 5400 |                      ? (BitWidth % APINT_BITS_PER_WORD)\n",
      "      |                         ~~~~~~~~ ^ ~~~~~~~~~~~~~~~~~~~\n",
      "7 warnings and 10 errors generated.\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to compile project \"myproject\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# modify the config as desired\u001b[39;00m\n\u001b[32m     17\u001b[39m hls_model = hls4ml.converters.convert_from_onnx_model(\n\u001b[32m     18\u001b[39m     model,\n\u001b[32m     19\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33mmy-hls-test\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     hls_config=config,\n\u001b[32m     23\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mhls_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/deep-learning-system-design/.venv/lib/python3.11/site-packages/hls4ml/model/graph.py:803\u001b[39m, in \u001b[36mModelGraph.compile\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    798\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compile the generated project and link the library into current environment.\u001b[39;00m\n\u001b[32m    799\u001b[39m \n\u001b[32m    800\u001b[39m \u001b[33;03mUsers should call this function if they want to use `predict` functionality for simulation.\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;28mself\u001b[39m.write()\n\u001b[32m--> \u001b[39m\u001b[32m803\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/deep-learning-system-design/.venv/lib/python3.11/site-packages/hls4ml/model/graph.py:806\u001b[39m, in \u001b[36mModelGraph._compile\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m     lib_name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._top_function_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    808\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m platform.system() == \u001b[33m\"\u001b[39m\u001b[33mLinux\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/deep-learning-system-design/.venv/lib/python3.11/site-packages/hls4ml/backends/fpga/fpga_backend.py:189\u001b[39m, in \u001b[36mFPGABackend.compile\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret_val.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m    188\u001b[39m     \u001b[38;5;28mprint\u001b[39m(ret_val.stdout)\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFailed to compile project \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel.config.get_project_name()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    190\u001b[39m lib_name = \u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m/firmware/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.so\u001b[39m\u001b[33m'\u001b[39m.format(\n\u001b[32m    191\u001b[39m     model.config.get_output_dir(), model.config.get_project_name(), model.config.get_config_value(\u001b[33m'\u001b[39m\u001b[33mStamp\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    192\u001b[39m )\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m lib_name\n",
      "\u001b[31mException\u001b[39m: Failed to compile project \"myproject\""
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.channels_last import ConvertToChannelsLastAndClean\n",
    "from qonnx.transformation.gemm_to_matmul import GemmToMatMul\n",
    "from qonnx.util.cleanup import cleanup_model\n",
    "\n",
    "model = ModelWrapper(ONNX_FILE_NAME)\n",
    "model = cleanup_model(model)\n",
    "model = model.transform(ConvertToChannelsLastAndClean())\n",
    "model = model.transform(GemmToMatMul())\n",
    "model = cleanup_model(model)\n",
    "\n",
    "config = hls4ml.utils.config.config_from_onnx_model(\n",
    "    model, granularity=\"name\", backend=\"Vitis\", default_precision=\"fixed<16,6>\"\n",
    ")\n",
    "# modify the config as desired\n",
    "hls_model = hls4ml.converters.convert_from_onnx_model(\n",
    "    model,\n",
    "    output_dir=\"my-hls-test\",\n",
    "    io_type=\"io_stream\",\n",
    "    backend=\"Vitis\",\n",
    "    hls_config=config,\n",
    ")\n",
    "hls_model.compile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-system-design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
